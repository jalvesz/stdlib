#:include "common.fypp"
#:set R_KINDS_TYPES = list(zip(REAL_KINDS, REAL_TYPES, REAL_SUFFIX))
#:set C_KINDS_TYPES = list(zip(CMPLX_KINDS, CMPLX_TYPES, CMPLX_SUFFIX))
#:set KINDS_TYPES = R_KINDS_TYPES+C_KINDS_TYPES

#! Allow for integer or character norm input: i.e., norm(a,2) or norm(a, '2')
#:set INPUT_TYPE    = ["character(len=*)","integer(ilp)"]
#:set INPUT_SHORT   = ["char","int"]
#:set INPUT_OPTIONS = list(zip(INPUT_TYPE,INPUT_SHORT))

! Sparse matrix norms implementation submodule
submodule(stdlib_sparse_norms) stdlib_sparse_norms_imp
    use stdlib_sparse_constants
    use stdlib_sparse_kinds
    use stdlib_linalg_state, only: linalg_state_type, linalg_error_handling, LINALG_ERROR, &
        LINALG_INTERNAL_ERROR, LINALG_VALUE_ERROR     
    use ieee_arithmetic, only: ieee_is_finite
    implicit none
    
    character(*), parameter :: this = 'sparse_norm'
    
    !> List of internal norm flags
    integer(ilp), parameter :: NORM_ONE       = 1_ilp 
    integer(ilp), parameter :: NORM_TWO       = 2_ilp
    integer(ilp), parameter :: NORM_POW_FIRST = 3_ilp       
    integer(ilp), parameter :: NORM_INF       = +huge(0_ilp) ! infinity norm 
    integer(ilp), parameter :: NORM_POW_LAST  = NORM_INF - 1_ilp
    integer(ilp), parameter :: NORM_MINUSINF  = -huge(0_ilp)
    
    interface parse_norm_type
        module procedure parse_norm_type_integer
        module procedure parse_norm_type_character
    end interface parse_norm_type
    
    contains
    
    !> Parse norm type from an integer user input
    pure subroutine parse_norm_type_integer(order,norm_type,err)
        !> User input value
        integer(ilp), intent(in) :: order
        !> Return value: norm type
        integer(ilp), intent(out) :: norm_type
        !> State return flag
        type(linalg_state_type), intent(out) :: err
        
        select case (order)
           case (1_ilp)
               norm_type = NORM_ONE
           case (2_ilp)
               norm_type = NORM_TWO
           case (3_ilp:NORM_POW_LAST)
               norm_type = order
           case (NORM_INF:)
               norm_type = NORM_INF
           case (:NORM_MINUSINF)
               norm_type = NORM_MINUSINF
           
           case default
               norm_type = NORM_ONE
               err = linalg_state_type(this,LINALG_ERROR,'Input norm type ',order,' is not recognized.')
        end select    
        
    end subroutine parse_norm_type_integer

    pure subroutine parse_norm_type_character(order,norm_type,err)
        !> User input value
        character(len=*), intent(in) :: order
        !> Return value: norm type
        integer(ilp), intent(out) :: norm_type
        !> State return flag
        type(linalg_state_type), intent(out) :: err
        
        integer(ilp) :: int_order,read_err
        
        select case (order)
           case ('inf','Inf','INF')
              norm_type = NORM_INF
           case ('-inf','-Inf','-INF')
              norm_type = NORM_MINUSINF
           case ('Euclidean','euclidean','EUCLIDEAN','Frobenius','frobenius','FROBENIUS','Fro','fro','frob')
              norm_type = NORM_TWO
           case default
            
              ! Check if this input can be read as an integer
              read(order,*,iostat=read_err) int_order
              if (read_err/=0) then 
                 ! Cannot read as an integer
                 norm_type = NORM_ONE
                 err = linalg_state_type(this,LINALG_ERROR,'Input norm type ',order,' is not recognized.')                 
              else
                 call parse_norm_type_integer(int_order,norm_type,err)
              endif  

        end select    
        
    end subroutine parse_norm_type_character

    #:for it,ii in INPUT_OPTIONS
    #:for k, t, s in KINDS_TYPES

    !> COO (Coordinate) format norm
    module function sparse_norm_${ii}$_coo_${s}$(matrix, order, err) result(nrm)
        !> Input COO sparse matrix
        class(COO_${s}$_type), intent(in) :: matrix
        !> Order of the matrix norm being computed.
        ${it}$, intent(in) :: order
        !> [optional] state return flag. On error if not requested, the code will stop
        type(linalg_state_type), intent(out), optional :: err
        !> Norm of the matrix.
        real(${k}$) :: nrm
        
        type(linalg_state_type) :: err_
        integer(ilp) :: norm_request, i
        real(${k}$) :: rorder
        
        ! Initialize norm to zero
        nrm = 0.0_${k}$
        
        ! Check matrix validity
        if (matrix%nrows <= 0 .or. matrix%ncols <= 0 .or. matrix%nnz < 0) then
            err_ = linalg_state_type(this,LINALG_VALUE_ERROR,'invalid sparse matrix dimensions')
            call linalg_error_handling(err_,err)
            return
        end if
        
        if (matrix%nnz == 0) then
            ! Empty matrix has norm 0
            call linalg_error_handling(err_,err)
            return
        end if
        
        ! Check norm request
        call parse_norm_type(order,norm_request,err_)
        if (err_%error()) then 
            call linalg_error_handling(err_,err)
            return
        endif         
        
        ! Compute norm based on request
        select case(norm_request)
            case(NORM_ONE)
                ! 1-norm: maximum absolute column sum
                call sparse_norm_one_coo_${s}$(matrix, nrm)
            case(NORM_TWO)            
                ! Frobenius norm: sqrt(sum(|a_ij|^2))
                call sparse_norm_frobenius_coo_${s}$(matrix, nrm)
            case(NORM_INF)
                ! Infinity norm: maximum absolute row sum
                call sparse_norm_inf_coo_${s}$(matrix, nrm)
            case(NORM_MINUSINF)
                ! Minimum of absolute values
                call sparse_norm_minusinf_coo_${s}$(matrix, nrm)
            case (NORM_POW_FIRST:NORM_POW_LAST)
                ! p-norm: (sum(|a_ij|^p))^(1/p)
                call sparse_norm_p_coo_${s}$(matrix, norm_request, nrm)
        end select
        
        call linalg_error_handling(err_,err)
        
    end function sparse_norm_${ii}$_coo_${s}$

    !> CSR (Compressed Sparse Row) format norm  
    module function sparse_norm_${ii}$_csr_${s}$(matrix, order, err) result(nrm)
        !> Input CSR sparse matrix
        class(CSR_${s}$_type), intent(in) :: matrix
        !> Order of the matrix norm being computed.
        ${it}$, intent(in) :: order
        !> [optional] state return flag. On error if not requested, the code will stop
        type(linalg_state_type), intent(out), optional :: err
        !> Norm of the matrix.
        real(${k}$) :: nrm
        
        type(linalg_state_type) :: err_
        integer(ilp) :: norm_request, i
        real(${k}$) :: rorder
        
        ! Initialize norm to zero
        nrm = 0.0_${k}$
        
        ! Check matrix validity
        if (matrix%nrows <= 0 .or. matrix%ncols <= 0 .or. matrix%nnz < 0) then
            err_ = linalg_state_type(this,LINALG_VALUE_ERROR,'invalid sparse matrix dimensions')
            call linalg_error_handling(err_,err)
            return
        end if
        
        if (matrix%nnz == 0) then
            ! Empty matrix has norm 0
            call linalg_error_handling(err_,err)
            return
        end if
        
        ! Check norm request
        call parse_norm_type(order,norm_request,err_)
        if (err_%error()) then 
            call linalg_error_handling(err_,err)
            return
        endif         
        
        ! Compute norm based on request
        select case(norm_request)
            case(NORM_ONE)
                ! 1-norm: maximum absolute column sum
                call sparse_norm_one_csr_${s}$(matrix, nrm)
            case(NORM_TWO)            
                ! Frobenius norm: sqrt(sum(|a_ij|^2))
                call sparse_norm_frobenius_csr_${s}$(matrix, nrm)
            case(NORM_INF)
                ! Infinity norm: maximum absolute row sum
                call sparse_norm_inf_csr_${s}$(matrix, nrm)
            case(NORM_MINUSINF)
                ! Minimum of absolute values
                call sparse_norm_minusinf_csr_${s}$(matrix, nrm)
            case (NORM_POW_FIRST:NORM_POW_LAST)
                ! p-norm: (sum(|a_ij|^p))^(1/p)
                call sparse_norm_p_csr_${s}$(matrix, norm_request, nrm)
        end select
        
        call linalg_error_handling(err_,err)
        
    end function sparse_norm_${ii}$_csr_${s}$

    !> CSC (Compressed Sparse Column) format norm
    module function sparse_norm_${ii}$_csc_${s}$(matrix, order, err) result(nrm)
        !> Input CSC sparse matrix
        class(CSC_${s}$_type), intent(in) :: matrix
        !> Order of the matrix norm being computed.
        ${it}$, intent(in) :: order
        !> [optional] state return flag. On error if not requested, the code will stop
        type(linalg_state_type), intent(out), optional :: err
        !> Norm of the matrix.
        real(${k}$) :: nrm
        
        type(linalg_state_type) :: err_
        integer(ilp) :: norm_request, i
        real(${k}$) :: rorder
        
        ! Initialize norm to zero
        nrm = 0.0_${k}$
        
        ! Check matrix validity
        if (matrix%nrows <= 0 .or. matrix%ncols <= 0 .or. matrix%nnz < 0) then
            err_ = linalg_state_type(this,LINALG_VALUE_ERROR,'invalid sparse matrix dimensions')
            call linalg_error_handling(err_,err)
            return
        end if
        
        if (matrix%nnz == 0) then
            ! Empty matrix has norm 0
            call linalg_error_handling(err_,err)
            return
        end if
        
        ! Check norm request
        call parse_norm_type(order,norm_request,err_)
        if (err_%error()) then 
            call linalg_error_handling(err_,err)
            return
        endif         
        
        ! Compute norm based on request
        select case(norm_request)
            case(NORM_ONE)
                ! 1-norm: maximum absolute column sum
                call sparse_norm_one_csc_${s}$(matrix, nrm)
            case(NORM_TWO)            
                ! Frobenius norm: sqrt(sum(|a_ij|^2))
                call sparse_norm_frobenius_csc_${s}$(matrix, nrm)
            case(NORM_INF)
                ! Infinity norm: maximum absolute row sum
                call sparse_norm_inf_csc_${s}$(matrix, nrm)
            case(NORM_MINUSINF)
                ! Minimum of absolute values
                call sparse_norm_minusinf_csc_${s}$(matrix, nrm)
            case (NORM_POW_FIRST:NORM_POW_LAST)
                ! p-norm: (sum(|a_ij|^p))^(1/p)
                call sparse_norm_p_csc_${s}$(matrix, norm_request, nrm)
        end select
        
        call linalg_error_handling(err_,err)
        
    end function sparse_norm_${ii}$_csc_${s}$

    !> ELL (ELLPACK) format norm
    module function sparse_norm_${ii}$_ell_${s}$(matrix, order, err) result(nrm)
        !> Input ELL sparse matrix
        class(ELL_${s}$_type), intent(in) :: matrix
        !> Order of the matrix norm being computed.
        ${it}$, intent(in) :: order
        !> [optional] state return flag. On error if not requested, the code will stop
        type(linalg_state_type), intent(out), optional :: err
        !> Norm of the matrix.
        real(${k}$) :: nrm
        
        type(linalg_state_type) :: err_
        integer(ilp) :: norm_request, i, j
        real(${k}$) :: rorder
        
        ! Initialize norm to zero
        nrm = 0.0_${k}$
        
        ! Check matrix validity
        if (matrix%nrows <= 0 .or. matrix%ncols <= 0 .or. matrix%K < 0) then
            err_ = linalg_state_type(this,LINALG_VALUE_ERROR,'invalid sparse matrix dimensions')
            call linalg_error_handling(err_,err)
            return
        end if
        
        if (matrix%K == 0) then
            ! Empty matrix has norm 0
            call linalg_error_handling(err_,err)
            return
        end if
        
        ! Check norm request
        call parse_norm_type(order,norm_request,err_)
        if (err_%error()) then 
            call linalg_error_handling(err_,err)
            return
        endif         
        
        ! Compute norm based on request
        select case(norm_request)
            case(NORM_ONE)
                ! 1-norm: maximum absolute column sum
                call sparse_norm_one_ell_${s}$(matrix, nrm)
            case(NORM_TWO)            
                ! Frobenius norm: sqrt(sum(|a_ij|^2))
                call sparse_norm_frobenius_ell_${s}$(matrix, nrm)
            case(NORM_INF)
                ! Infinity norm: maximum absolute row sum
                call sparse_norm_inf_ell_${s}$(matrix, nrm)
            case(NORM_MINUSINF)
                ! Minimum of absolute values
                call sparse_norm_minusinf_ell_${s}$(matrix, nrm)
            case (NORM_POW_FIRST:NORM_POW_LAST)
                ! p-norm: (sum(|a_ij|^p))^(1/p)
                call sparse_norm_p_ell_${s}$(matrix, norm_request, nrm)
        end select
        
        call linalg_error_handling(err_,err)
        
    end function sparse_norm_${ii}$_ell_${s}$

    !> SELLC (SELL-C) format norm
    module function sparse_norm_${ii}$_sellc_${s}$(matrix, order, err) result(nrm)
        !> Input SELLC sparse matrix
        class(SELLC_${s}$_type), intent(in) :: matrix
        !> Order of the matrix norm being computed.
        ${it}$, intent(in) :: order
        !> [optional] state return flag. On error if not requested, the code will stop
        type(linalg_state_type), intent(out), optional :: err
        !> Norm of the matrix.
        real(${k}$) :: nrm
        
        type(linalg_state_type) :: err_
        integer(ilp) :: norm_request, i, j, chunk_id, num_chunks
        real(${k}$) :: rorder
        
        ! Initialize norm to zero
        nrm = 0.0_${k}$
        
        ! Check matrix validity
        if (matrix%nrows <= 0 .or. matrix%ncols <= 0 .or. matrix%chunk_size <= 0) then
            err_ = linalg_state_type(this,LINALG_VALUE_ERROR,'invalid sparse matrix dimensions')
            call linalg_error_handling(err_,err)
            return
        end if
        
        ! Check norm request
        call parse_norm_type(order,norm_request,err_)
        if (err_%error()) then 
            call linalg_error_handling(err_,err)
            return
        endif         
        
        ! Compute norm based on request
        select case(norm_request)
            case(NORM_ONE)
                ! 1-norm: maximum absolute column sum
                call sparse_norm_one_sellc_${s}$(matrix, nrm)
            case(NORM_TWO)            
                ! Frobenius norm: sqrt(sum(|a_ij|^2))
                call sparse_norm_frobenius_sellc_${s}$(matrix, nrm)
            case(NORM_INF)
                ! Infinity norm: maximum absolute row sum
                call sparse_norm_inf_sellc_${s}$(matrix, nrm)
            case(NORM_MINUSINF)
                ! Minimum of absolute values
                call sparse_norm_minusinf_sellc_${s}$(matrix, nrm)
            case (NORM_POW_FIRST:NORM_POW_LAST)
                ! p-norm: (sum(|a_ij|^p))^(1/p)
                call sparse_norm_p_sellc_${s}$(matrix, norm_request, nrm)
        end select
        
        call linalg_error_handling(err_,err)
        
    end function sparse_norm_${ii}$_sellc_${s}$

    #:endfor
    #:endfor

    ! Helper functions for computing specific norms
    
    #:for k, t, s in KINDS_TYPES
    
    !> COO 1-norm helper
    pure subroutine sparse_norm_one_coo_${s}$(matrix, nrm)
        class(COO_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, row_idx, col_idx
        real(${k}$), allocatable :: col_sums(:)
        real(${k}$) :: val
        
        allocate(col_sums(matrix%ncols), source=0.0_${k}$)
        
        do i = 1, matrix%nnz
            row_idx = matrix%index(1,i)  ! row index
            col_idx = matrix%index(2,i)  ! column index
            val = abs(matrix%data(i))
            
            if (row_idx >= 1 .and. row_idx <= matrix%nrows .and. &
                col_idx >= 1 .and. col_idx <= matrix%ncols) then
                
                ! Add contribution to column col_idx
                col_sums(col_idx) = col_sums(col_idx) + val
                
                ! For symmetric storage, add symmetric contribution
                if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                    ! Lower triangular: element (row_idx, col_idx) implies (col_idx, row_idx) exists
                    col_sums(row_idx) = col_sums(row_idx) + val
                else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                    ! Upper triangular: element (row_idx, col_idx) implies (col_idx, row_idx) exists
                    col_sums(row_idx) = col_sums(row_idx) + val
                end if
            end if
        end do
        
        nrm = maxval(col_sums)
        
    end subroutine sparse_norm_one_coo_${s}$
    
    !> COO infinity-norm helper
    pure subroutine sparse_norm_inf_coo_${s}$(matrix, nrm)
        class(COO_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, row_idx, col_idx
        real(${k}$), allocatable :: row_sums(:)
        real(${k}$) :: val
        
        allocate(row_sums(matrix%nrows), source=0.0_${k}$)
        
        do i = 1, matrix%nnz
            row_idx = matrix%index(1,i)  ! row index
            col_idx = matrix%index(2,i)  ! column index
            val = abs(matrix%data(i))
            
            if (row_idx >= 1 .and. row_idx <= matrix%nrows .and. &
                col_idx >= 1 .and. col_idx <= matrix%ncols) then
                
                ! Add contribution to row row_idx
                row_sums(row_idx) = row_sums(row_idx) + val
                
                ! For symmetric storage, add symmetric contribution
                if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                    ! Lower triangular: element (row_idx, col_idx) implies (col_idx, row_idx) exists
                    row_sums(col_idx) = row_sums(col_idx) + val
                else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                    ! Upper triangular: element (row_idx, col_idx) implies (col_idx, row_idx) exists
                    row_sums(col_idx) = row_sums(col_idx) + val
                end if
            end if
        end do
        
        nrm = maxval(row_sums)
        
    end subroutine sparse_norm_inf_coo_${s}$

    !> CSR 1-norm helper
    pure subroutine sparse_norm_one_csr_${s}$(matrix, nrm)
        class(CSR_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, j, k, row_idx, col_idx
        real(${k}$), allocatable :: col_sums(:)
        real(${k}$) :: val
        
        allocate(col_sums(matrix%ncols), source=0.0_${k}$)
        
        do i = 1, matrix%nrows
            do k = matrix%rowptr(i), matrix%rowptr(i+1)-1
                row_idx = i
                col_idx = matrix%col(k)
                val = abs(matrix%data(k))
                
                if (col_idx >= 1 .and. col_idx <= matrix%ncols) then
                    ! Add contribution to column col_idx
                    col_sums(col_idx) = col_sums(col_idx) + val
                    
                    ! For symmetric storage, add symmetric contribution
                    if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                        col_sums(row_idx) = col_sums(row_idx) + val
                    else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                        col_sums(row_idx) = col_sums(row_idx) + val
                    end if
                end if
            end do
        end do
        
        nrm = maxval(col_sums)
        
    end subroutine sparse_norm_one_csr_${s}$
    
    !> CSR infinity-norm helper
    pure subroutine sparse_norm_inf_csr_${s}$(matrix, nrm)
        class(CSR_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, k, row_idx, col_idx
        real(${k}$), allocatable :: row_sums(:)
        real(${k}$) :: val
        
        allocate(row_sums(matrix%nrows), source=0.0_${k}$)
        
        do i = 1, matrix%nrows
            do k = matrix%rowptr(i), matrix%rowptr(i+1)-1
                row_idx = i
                col_idx = matrix%col(k)
                val = abs(matrix%data(k))
                
                ! Add contribution to row row_idx
                row_sums(row_idx) = row_sums(row_idx) + val
                
                ! For symmetric storage, add symmetric contribution
                if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                    row_sums(col_idx) = row_sums(col_idx) + val
                else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                    row_sums(col_idx) = row_sums(col_idx) + val
                end if
            end do
        end do
        
        nrm = maxval(row_sums)
        
    end subroutine sparse_norm_inf_csr_${s}$

    !> CSC 1-norm helper
    pure subroutine sparse_norm_one_csc_${s}$(matrix, nrm)
        class(CSC_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: j, k, row_idx, col_idx
        real(${k}$), allocatable :: col_sums(:)
        real(${k}$) :: val
        
        allocate(col_sums(matrix%ncols), source=0.0_${k}$)
        
        do j = 1, matrix%ncols
            do k = matrix%colptr(j), matrix%colptr(j+1)-1
                row_idx = matrix%row(k)
                col_idx = j
                val = abs(matrix%data(k))
                
                ! Add contribution to column col_idx
                col_sums(col_idx) = col_sums(col_idx) + val
                
                ! For symmetric storage, add symmetric contribution
                if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                    col_sums(row_idx) = col_sums(row_idx) + val
                else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                    col_sums(row_idx) = col_sums(row_idx) + val
                end if
            end do
        end do
        
        nrm = maxval(col_sums)
        
    end subroutine sparse_norm_one_csc_${s}$
    
    !> CSC infinity-norm helper
    pure subroutine sparse_norm_inf_csc_${s}$(matrix, nrm)
        class(CSC_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: j, k, row_idx, col_idx
        real(${k}$), allocatable :: row_sums(:)
        real(${k}$) :: val
        
        allocate(row_sums(matrix%nrows), source=0.0_${k}$)
        
        do j = 1, matrix%ncols
            do k = matrix%colptr(j), matrix%colptr(j+1)-1
                row_idx = matrix%row(k)
                col_idx = j
                val = abs(matrix%data(k))
                
                if (row_idx >= 1 .and. row_idx <= matrix%nrows) then
                    ! Add contribution to row row_idx
                    row_sums(row_idx) = row_sums(row_idx) + val
                    
                    ! For symmetric storage, add symmetric contribution
                    if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                        row_sums(col_idx) = row_sums(col_idx) + val
                    else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                        row_sums(col_idx) = row_sums(col_idx) + val
                    end if
                end if
            end do
        end do
        
        nrm = maxval(row_sums)
        
    end subroutine sparse_norm_inf_csc_${s}$

    !> ELL 1-norm helper
    pure subroutine sparse_norm_one_ell_${s}$(matrix, nrm)
        class(ELL_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, j, row_idx, col_idx
        real(${k}$), allocatable :: col_sums(:)
        real(${k}$) :: val
        
        allocate(col_sums(matrix%ncols), source=0.0_${k}$)
        
        do i = 1, matrix%nrows
            do j = 1, matrix%K
                col_idx = matrix%index(i,j)
                if (col_idx > 0 .and. col_idx <= matrix%ncols) then
                    row_idx = i
                    val = abs(matrix%data(i,j))
                    
                    ! Add contribution to column col_idx
                    col_sums(col_idx) = col_sums(col_idx) + val
                    
                    ! For symmetric storage, add symmetric contribution
                    if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                        col_sums(row_idx) = col_sums(row_idx) + val
                    else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                        col_sums(row_idx) = col_sums(row_idx) + val
                    end if
                end if
            end do
        end do
        
        nrm = maxval(col_sums)
        
    end subroutine sparse_norm_one_ell_${s}$
    
    !> ELL infinity-norm helper
    pure subroutine sparse_norm_inf_ell_${s}$(matrix, nrm)
        class(ELL_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, j, row_idx, col_idx
        real(${k}$), allocatable :: row_sums(:)
        real(${k}$) :: val
        
        allocate(row_sums(matrix%nrows), source=0.0_${k}$)
        
        do i = 1, matrix%nrows
            do j = 1, matrix%K
                if (matrix%index(i,j) > 0) then
                    row_idx = i
                    col_idx = matrix%index(i,j)
                    val = abs(matrix%data(i,j))
                    
                    ! Add contribution to row row_idx
                    row_sums(row_idx) = row_sums(row_idx) + val
                    
                    ! For symmetric storage, add symmetric contribution
                    if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                        row_sums(col_idx) = row_sums(col_idx) + val
                    else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                        row_sums(col_idx) = row_sums(col_idx) + val
                    end if
                end if
            end do
        end do
        
        nrm = maxval(row_sums)
        
    end subroutine sparse_norm_inf_ell_${s}$

    !> SELLC 1-norm helper
    pure subroutine sparse_norm_one_sellc_${s}$(matrix, nrm)
        class(SELLC_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, j, chunk_id, num_chunks, col_idx, global_row_id
        real(${k}$), allocatable :: col_sums(:)
        real(${k}$) :: val
        
        allocate(col_sums(matrix%ncols), source=0.0_${k}$)
        
        num_chunks = (matrix%nrows + matrix%chunk_size - 1) / matrix%chunk_size
        do chunk_id = 1, num_chunks
            do j = 1, matrix%chunk_size
                do i = matrix%rowptr(chunk_id), matrix%rowptr(chunk_id+1)-1
                    col_idx = matrix%col(j,i)
                    if (col_idx > 0 .and. col_idx <= matrix%ncols) then
                        global_row_id = (chunk_id-1) * matrix%chunk_size + j
                        val = abs(matrix%data(j,i))
                        
                        ! Add contribution to column col_idx
                        col_sums(col_idx) = col_sums(col_idx) + val
                        
                        ! For symmetric storage, add symmetric contribution
                        if (matrix%storage == sparse_lower .and. global_row_id > col_idx) then
                            col_sums(global_row_id) = col_sums(global_row_id) + val
                        else if (matrix%storage == sparse_upper .and. global_row_id < col_idx) then
                            col_sums(global_row_id) = col_sums(global_row_id) + val
                        end if
                    end if
                end do
            end do
        end do
        
        nrm = maxval(col_sums)
        
    end subroutine sparse_norm_one_sellc_${s}$
    
    !> SELLC infinity-norm helper
    pure subroutine sparse_norm_inf_sellc_${s}$(matrix, nrm)
        class(SELLC_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, j, chunk_id, num_chunks, local_row_id, global_row_id, col_idx
        real(${k}$), allocatable :: row_sums(:)
        real(${k}$) :: val
        
        allocate(row_sums(matrix%nrows), source=0.0_${k}$)
        
        num_chunks = (matrix%nrows + matrix%chunk_size - 1) / matrix%chunk_size
        do chunk_id = 1, num_chunks
            do j = 1, matrix%chunk_size
                do i = matrix%rowptr(chunk_id), matrix%rowptr(chunk_id+1)-1
                    col_idx = matrix%col(j,i)
                    if (col_idx > 0) then
                        global_row_id = (chunk_id-1) * matrix%chunk_size + j
                        if (global_row_id <= matrix%nrows) then
                            val = abs(matrix%data(j,i))
                            
                            ! Add contribution to row global_row_id
                            row_sums(global_row_id) = row_sums(global_row_id) + val
                            
                            ! For symmetric storage, add symmetric contribution
                            if (matrix%storage == sparse_lower .and. global_row_id > col_idx) then
                                row_sums(col_idx) = row_sums(col_idx) + val
                            else if (matrix%storage == sparse_upper .and. global_row_id < col_idx) then
                                row_sums(col_idx) = row_sums(col_idx) + val
                            end if
                        end if
                    end if
                end do
            end do
        end do
        
        nrm = maxval(row_sums)
        
    end subroutine sparse_norm_inf_sellc_${s}$

    !> COO Frobenius norm helper
    pure subroutine sparse_norm_frobenius_coo_${s}$(matrix, nrm)
        class(COO_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, row_idx, col_idx
        real(${k}$) :: val_sq
        
        nrm = 0.0_${k}$
        
        do i = 1, matrix%nnz
            row_idx = matrix%index(1,i)  ! row index
            col_idx = matrix%index(2,i)  ! column index
            val_sq = abs(matrix%data(i))**2
            
            ! Add contribution from the stored element
            nrm = nrm + val_sq
            
            ! For symmetric storage, add symmetric contribution (but not for diagonal)
            if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                ! Lower triangular: element (row_idx, col_idx) implies (col_idx, row_idx) exists
                nrm = nrm + val_sq
            else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                ! Upper triangular: element (row_idx, col_idx) implies (col_idx, row_idx) exists
                nrm = nrm + val_sq
            end if
        end do
        
        nrm = sqrt(nrm)
        
    end subroutine sparse_norm_frobenius_coo_${s}$

    !> COO minimum absolute value norm helper
    pure subroutine sparse_norm_minusinf_coo_${s}$(matrix, nrm)
        class(COO_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        if (matrix%nnz > 0) then
            nrm = minval(abs(matrix%data))
        else
            nrm = 0.0_${k}$
        end if
        
    end subroutine sparse_norm_minusinf_coo_${s}$

    !> COO p-norm helper
    pure subroutine sparse_norm_p_coo_${s}$(matrix, p, nrm)
        class(COO_${s}$_type), intent(in) :: matrix
        integer(ilp), intent(in) :: p
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, row_idx, col_idx
        real(${k}$) :: val_p, rorder
        
        nrm = 0.0_${k}$
        rorder = 1.0_${k}$ / p
        
        do i = 1, matrix%nnz
            row_idx = matrix%index(1,i)  ! row index
            col_idx = matrix%index(2,i)  ! column index
            val_p = abs(matrix%data(i)) ** p
            
            ! Add contribution from the stored element
            nrm = nrm + val_p
            
            ! For symmetric storage, add symmetric contribution (but not for diagonal)
            if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                ! Lower triangular: element (row_idx, col_idx) implies (col_idx, row_idx) exists
                nrm = nrm + val_p
            else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                ! Upper triangular: element (row_idx, col_idx) implies (col_idx, row_idx) exists
                nrm = nrm + val_p
            end if
        end do
        
        nrm = nrm ** rorder
        
    end subroutine sparse_norm_p_coo_${s}$

    !> CSR Frobenius norm helper
    pure subroutine sparse_norm_frobenius_csr_${s}$(matrix, nrm)
        class(CSR_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, k, row_idx, col_idx
        real(${k}$) :: val_sq
        
        nrm = 0.0_${k}$
        
        do i = 1, matrix%nrows
            do k = matrix%rowptr(i), matrix%rowptr(i+1)-1
                row_idx = i
                col_idx = matrix%col(k)
                val_sq = abs(matrix%data(k))**2
                
                ! Add contribution from the stored element
                nrm = nrm + val_sq
                
                ! For symmetric storage, add symmetric contribution (but not for diagonal)
                if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                    nrm = nrm + val_sq
                else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                    nrm = nrm + val_sq
                end if
            end do
        end do
        
        nrm = sqrt(nrm)
        
    end subroutine sparse_norm_frobenius_csr_${s}$

    !> CSR minimum absolute value norm helper
    pure subroutine sparse_norm_minusinf_csr_${s}$(matrix, nrm)
        class(CSR_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        if (matrix%nnz > 0) then
            nrm = minval(abs(matrix%data))
        else
            nrm = 0.0_${k}$
        end if
        
    end subroutine sparse_norm_minusinf_csr_${s}$

    !> CSR p-norm helper
    pure subroutine sparse_norm_p_csr_${s}$(matrix, p, nrm)
        class(CSR_${s}$_type), intent(in) :: matrix
        integer(ilp), intent(in) :: p
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, k, row_idx, col_idx
        real(${k}$) :: val_p, rorder
        
        nrm = 0.0_${k}$
        rorder = 1.0_${k}$ / p
        
        do i = 1, matrix%nrows
            do k = matrix%rowptr(i), matrix%rowptr(i+1)-1
                row_idx = i
                col_idx = matrix%col(k)
                val_p = abs(matrix%data(k)) ** p
                
                ! Add contribution from the stored element
                nrm = nrm + val_p
                
                ! For symmetric storage, add symmetric contribution (but not for diagonal)
                if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                    nrm = nrm + val_p
                else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                    nrm = nrm + val_p
                end if
            end do
        end do
        
        nrm = nrm ** rorder
        
    end subroutine sparse_norm_p_csr_${s}$

    !> CSC Frobenius norm helper
    pure subroutine sparse_norm_frobenius_csc_${s}$(matrix, nrm)
        class(CSC_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: j, k, row_idx, col_idx
        real(${k}$) :: val_sq
        
        nrm = 0.0_${k}$
        
        do j = 1, matrix%ncols
            do k = matrix%colptr(j), matrix%colptr(j+1)-1
                row_idx = matrix%row(k)
                col_idx = j
                val_sq = abs(matrix%data(k))**2
                
                ! Add contribution from the stored element
                nrm = nrm + val_sq
                
                ! For symmetric storage, add symmetric contribution (but not for diagonal)
                if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                    nrm = nrm + val_sq
                else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                    nrm = nrm + val_sq
                end if
            end do
        end do
        
        nrm = sqrt(nrm)
        
    end subroutine sparse_norm_frobenius_csc_${s}$

    !> CSC minimum absolute value norm helper
    pure subroutine sparse_norm_minusinf_csc_${s}$(matrix, nrm)
        class(CSC_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        if (matrix%nnz > 0) then
            nrm = minval(abs(matrix%data))
        else
            nrm = 0.0_${k}$
        end if
        
    end subroutine sparse_norm_minusinf_csc_${s}$

    !> CSC p-norm helper
    pure subroutine sparse_norm_p_csc_${s}$(matrix, p, nrm)
        class(CSC_${s}$_type), intent(in) :: matrix
        integer(ilp), intent(in) :: p
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: j, k, row_idx, col_idx
        real(${k}$) :: val_p, rorder
        
        nrm = 0.0_${k}$
        rorder = 1.0_${k}$ / p
        
        do j = 1, matrix%ncols
            do k = matrix%colptr(j), matrix%colptr(j+1)-1
                row_idx = matrix%row(k)
                col_idx = j
                val_p = abs(matrix%data(k)) ** p
                
                ! Add contribution from the stored element
                nrm = nrm + val_p
                
                ! For symmetric storage, add symmetric contribution (but not for diagonal)
                if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                    nrm = nrm + val_p
                else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                    nrm = nrm + val_p
                end if
            end do
        end do
        
        nrm = nrm ** rorder
        
    end subroutine sparse_norm_p_csc_${s}$

    !> ELL Frobenius norm helper
    pure subroutine sparse_norm_frobenius_ell_${s}$(matrix, nrm)
        class(ELL_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, j, row_idx, col_idx
        real(${k}$) :: val_sq
        
        nrm = 0.0_${k}$
        
        do i = 1, matrix%nrows
            do j = 1, matrix%K
                if (matrix%index(i,j) > 0) then
                    row_idx = i
                    col_idx = matrix%index(i,j)
                    val_sq = abs(matrix%data(i,j))**2
                    
                    ! Add contribution from the stored element
                    nrm = nrm + val_sq
                    
                    ! For symmetric storage, add symmetric contribution (but not for diagonal)
                    if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                        nrm = nrm + val_sq
                    else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                        nrm = nrm + val_sq
                    end if
                end if
            end do
        end do
        
        nrm = sqrt(nrm)
        
    end subroutine sparse_norm_frobenius_ell_${s}$

    !> ELL minimum absolute value norm helper
    pure subroutine sparse_norm_minusinf_ell_${s}$(matrix, nrm)
        class(ELL_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, j
        
        nrm = huge(0.0_${k}$)
        do i = 1, matrix%nrows
            do j = 1, matrix%K
                if (matrix%index(i,j) > 0) then
                    nrm = min(nrm, abs(matrix%data(i,j)))
                end if
            end do
        end do
        if (nrm == huge(0.0_${k}$)) nrm = 0.0_${k}$
        
    end subroutine sparse_norm_minusinf_ell_${s}$

    !> ELL p-norm helper
    pure subroutine sparse_norm_p_ell_${s}$(matrix, p, nrm)
        class(ELL_${s}$_type), intent(in) :: matrix
        integer(ilp), intent(in) :: p
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, j, row_idx, col_idx
        real(${k}$) :: val_p, rorder
        
        nrm = 0.0_${k}$
        rorder = 1.0_${k}$ / p
        
        do i = 1, matrix%nrows
            do j = 1, matrix%K
                if (matrix%index(i,j) > 0) then
                    row_idx = i
                    col_idx = matrix%index(i,j)
                    val_p = abs(matrix%data(i,j)) ** p
                    
                    ! Add contribution from the stored element
                    nrm = nrm + val_p
                    
                    ! For symmetric storage, add symmetric contribution (but not for diagonal)
                    if (matrix%storage == sparse_lower .and. row_idx > col_idx) then
                        nrm = nrm + val_p
                    else if (matrix%storage == sparse_upper .and. row_idx < col_idx) then
                        nrm = nrm + val_p
                    end if
                end if
            end do
        end do
        
        nrm = nrm ** rorder
        
    end subroutine sparse_norm_p_ell_${s}$

    !> SELLC Frobenius norm helper
    pure subroutine sparse_norm_frobenius_sellc_${s}$(matrix, nrm)
        class(SELLC_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, j, chunk_id, num_chunks, local_row_id, global_row_id
        real(${k}$) :: val_sq
        
        nrm = 0.0_${k}$
        num_chunks = (matrix%nrows + matrix%chunk_size - 1) / matrix%chunk_size
        
        do chunk_id = 1, num_chunks
            do j = 1, matrix%chunk_size
                do i = matrix%rowptr(chunk_id), matrix%rowptr(chunk_id+1)-1
                    if (matrix%col(j,i) > 0) then
                        global_row_id = (chunk_id-1) * matrix%chunk_size + j
                        val_sq = abs(matrix%data(j,i))**2
                        
                        ! Add contribution from the stored element
                        nrm = nrm + val_sq
                        
                        ! For symmetric storage, add symmetric contribution (but not for diagonal)
                        if (matrix%storage == sparse_lower .and. global_row_id > matrix%col(j,i)) then
                            nrm = nrm + val_sq
                        else if (matrix%storage == sparse_upper .and. global_row_id < matrix%col(j,i)) then
                            nrm = nrm + val_sq
                        end if
                    end if
                end do
            end do
        end do
        
        nrm = sqrt(nrm)
        
    end subroutine sparse_norm_frobenius_sellc_${s}$

    !> SELLC minimum absolute value norm helper
    pure subroutine sparse_norm_minusinf_sellc_${s}$(matrix, nrm)
        class(SELLC_${s}$_type), intent(in) :: matrix
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, j, chunk_id, num_chunks
        
        nrm = huge(0.0_${k}$)
        num_chunks = (matrix%nrows + matrix%chunk_size - 1) / matrix%chunk_size
        do chunk_id = 1, num_chunks
            do j = 1, matrix%chunk_size
                do i = matrix%rowptr(chunk_id), matrix%rowptr(chunk_id+1)-1
                    if (matrix%col(j,i) > 0) then
                        nrm = min(nrm, abs(matrix%data(j,i)))
                    end if
                end do
            end do
        end do
        if (nrm == huge(0.0_${k}$)) nrm = 0.0_${k}$
        
    end subroutine sparse_norm_minusinf_sellc_${s}$

    !> SELLC p-norm helper
    pure subroutine sparse_norm_p_sellc_${s}$(matrix, p, nrm)
        class(SELLC_${s}$_type), intent(in) :: matrix
        integer(ilp), intent(in) :: p
        real(${k}$), intent(out) :: nrm
        
        integer(ilp) :: i, j, chunk_id, num_chunks, global_row_id
        real(${k}$) :: val_p, rorder
        
        nrm = 0.0_${k}$
        rorder = 1.0_${k}$ / p
        num_chunks = (matrix%nrows + matrix%chunk_size - 1) / matrix%chunk_size
        
        do chunk_id = 1, num_chunks
            do j = 1, matrix%chunk_size
                do i = matrix%rowptr(chunk_id), matrix%rowptr(chunk_id+1)-1
                    if (matrix%col(j,i) > 0) then
                        global_row_id = (chunk_id-1) * matrix%chunk_size + j
                        val_p = abs(matrix%data(j,i)) ** p
                        
                        ! Add contribution from the stored element
                        nrm = nrm + val_p
                        
                        ! For symmetric storage, add symmetric contribution (but not for diagonal)
                        if (matrix%storage == sparse_lower .and. global_row_id > matrix%col(j,i)) then
                            nrm = nrm + val_p
                        else if (matrix%storage == sparse_upper .and. global_row_id < matrix%col(j,i)) then
                            nrm = nrm + val_p
                        end if
                    end if
                end do
            end do
        end do
        
        nrm = nrm ** rorder
        
    end subroutine sparse_norm_p_sellc_${s}$

    #:endfor

end submodule stdlib_sparse_norms_imp